{"file_name": "docs/installation/production/index.md", "questions": ["How to set up a production installation of Tracardi?", "What is the recommended number of Tracardi API and GUI instances for a production installation?", "How should the Tracardi API cluster be configured?", "What is the recommended way to set up a load balancer for a Tracardi production installation?"], "answer": "# Production installation\nTracardi is a distributed system and as such should be installed on production servers. The installations described in\nthe previous sections are mainly used for testing purposes. A production installation should be built with at least five\nTracardi API instances, two instances of GUI, and three elasticsearch instances.\n\nSetting up an elastic search cluster is beyond Tracardi configuration and can be handled by ready to use cloud instances\nthat expose one IP but hide 3 and more instances of the database.\n\n## API and GUI\n\nThe production setup should have a clusters with Tracardi API and one cluster with Tracardi GUI (2 instances). GUI\ncluster should be accessible only from trusted network for security reasons. Although the cluster with Tracardi API may\nbe set up as one cluster we recommend running 2 clusters with slightly reconfigured instances.\n\nOne cluster, the one available on the Internet, consisting of at least 3 instances should be configured with\nenvironment variable `EXPOSE_GUI_API` set to `no`. This way the publicly available API will have only `/track` endpoint available.\nThis cluster will be used for event collection from the website on the Internet. All other endpoints that are needed for\nthe GUI will be disabled.\n\nAnother cluster, the one available in the internal network, or available on the Internet but restricted to certain set\nof IPs, should have the environment variable `EXPOSE_GUI_API` set to `yes`. This cluster will be used by GUI to control Tracardi.\n\n## Tracardi API cluster\n\nA single instance of Tracardi API (by default run from docker container) starts 25 workers. Each worker is able to\nhandle asynchronous connections.\n\nEach instance of Tracardi API should be run on a separate server (physical or virtual). The point is that in the event\nof failure, the other instances could take over the tasks of the failed instance. There is no obstacle to run more than\nthree Tracardi instances.\n\n!!! Tip\n\n    We recommend installing Tracardi inside a k8s environment. Kubernetes automatically can bring back to life failed\n    docker instances.\n\n## Load balancing\n\nA cluster of Tracardi instances (GUI or API) should be hidden behind the load balancer that will expose one IP to the\nworld and direct external traffic to individual instances. To avoid single point of failure create multiple instances of\nload balancer.  \nTracardi do not require long-lasting sticky sessions, so you can configure your DNS servers to return multiple A\nrecords (IP addresses) for your domain.\n\nThis kind of architecture will allow you to scale Tracardi for small and high traffic.\n\nIf Tracardi is configured to run in HTTPS mode, the load balancer should accept encrypted traffic. Requests inside the\ncluster may stay not encoded. This way, you can bypass the certificate management problems for each Tracardi instance."}